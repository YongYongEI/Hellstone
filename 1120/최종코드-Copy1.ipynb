{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffa79c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted process to use only available 5-day forecast data\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# OpenWeatherMap API key\n",
    "API_KEY = \"09806c8ab9fb92886b5a722c6359df79\"\n",
    "\n",
    "# District coordinates for weather fetching\n",
    "districts = {\n",
    "    \"동구\": (36.3241, 127.4349),\n",
    "    \"중구\": (36.317, 127.418),\n",
    "    \"서구\": (36.3528, 127.3823),\n",
    "    \"유성구\": (36.3832, 127.3308),\n",
    "    \"대덕구\": (36.3617, 127.4199),\n",
    "}\n",
    "\n",
    "# Weather condition mapping\n",
    "weather_mapping = {\n",
    "    \"clear sky\": \"맑음\",\n",
    "    \"few clouds\": \"흐림\",\n",
    "    \"scattered clouds\": \"흐림\",\n",
    "    \"broken clouds\": \"흐림\",\n",
    "    \"overcast clouds\": \"흐림\",\n",
    "    \"rain\": \"비\",\n",
    "    \"light rain\": \"비\",\n",
    "    \"moderate rain\": \"비\",\n",
    "    \"heavy rain\": \"비\",\n",
    "    \"shower rain\": \"비\",\n",
    "    \"snow\": \"눈\",\n",
    "    \"light snow\": \"눈\",\n",
    "    \"heavy snow\": \"눈\",\n",
    "    \"fog\": \"안개\",\n",
    "    \"mist\": \"안개\",\n",
    "    \"haze\": \"안개\",\n",
    "}\n",
    "\n",
    "weather_types = [\"맑음\", \"흐림\", \"비\", \"눈\", \"안개\"]\n",
    "default_weather = \"기타\"\n",
    "\n",
    "# Map weather descriptions to Korean terms\n",
    "def map_weather_description(description):\n",
    "    return weather_mapping.get(description, default_weather)\n",
    "\n",
    "# Fetch weather data for a specific latitude and longitude\n",
    "def get_weather(lat, lon):\n",
    "    url = f\"http://api.openweathermap.org/data/2.5/forecast\"\n",
    "    params = {\n",
    "        \"lat\": lat,\n",
    "        \"lon\": lon,\n",
    "        \"appid\": API_KEY,\n",
    "        \"units\": \"metric\",  # Use Celsius\n",
    "        \"lang\": \"en\",\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error fetching weather data: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "\n",
    "# Analyze weather data for available dates\n",
    "def analyze_weather(data):\n",
    "    weather_counts = defaultdict(lambda: defaultdict(int))\n",
    "    for item in data['list']:\n",
    "        date = item['dt_txt'].split()[0]\n",
    "        description = item['weather'][0]['description']\n",
    "        mapped_weather = map_weather_description(description)\n",
    "        weather_counts[date][mapped_weather] += 1\n",
    "    return weather_counts\n",
    "\n",
    "# Main process\n",
    "results = {}\n",
    "for district, (lat, lon) in districts.items():\n",
    "    weather_data = get_weather(lat, lon)\n",
    "    if weather_data:\n",
    "        results[district] = analyze_weather(weather_data)\n",
    "\n",
    "# Aggregate results for each district\n",
    "final_results = {district: defaultdict(int, {weather: 0 for weather in weather_types}) for district in districts.keys()}\n",
    "for district, weather_data in results.items():\n",
    "    for date, counts in weather_data.items():\n",
    "        for weather_type, count in counts.items():\n",
    "            final_results[district][weather_type] += count\n",
    "\n",
    "# Display results\n",
    "result_df = pd.DataFrame(final_results).fillna(0).astype(int)\n",
    "result_df.index.name = \"날씨 유형\"\n",
    "result_df.columns.name = \"지역\"\n",
    "result_df = result_df.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6bda80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'your_file_path.csv'  # Replace with your file path\n",
    "data = pd.read_csv(file_path)\n",
    "population_data = {\n",
    "    \"대덕구\": 337416,\n",
    "    \"동구\": 437280,\n",
    "    \"서구\": 917806,\n",
    "    \"유성구\": 738622,\n",
    "    \"중구\": 449064\n",
    "}\n",
    "\n",
    "# Preprocessing\n",
    "# Extract month from '년월' and convert to numeric\n",
    "data['월'] = data['년월'].str[-2:].astype(int)\n",
    "\n",
    "# Select input features and target variable\n",
    "features = ['맑음', '흐림', '비', '눈', '안개', '인구수', '월']\n",
    "target = 'ARI'\n",
    "\n",
    "# Drop rows with missing values\n",
    "cleaned_data = data.dropna(subset=features + [target])\n",
    "\n",
    "# Separate features and target\n",
    "X = cleaned_data[features]\n",
    "y = cleaned_data[target]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)  # Output layer for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=16, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Mean Squared Error: {loss}, Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Predict ARI values for test data\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283af4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add population data to result_df\n",
    "result_df[\"인구수\"] = result_df.index.map(population_data)\n",
    "\n",
    "# Add a \"월\" column (assuming the prediction is for the next month, e.g., 2 for February)\n",
    "result_df[\"월\"] = next_month  # Replace with the appropriate month if needed\n",
    "\n",
    "# Prepare data for prediction\n",
    "X_predict = result_df.reset_index(drop=True)\n",
    "\n",
    "# Ensure the columns match the trained model's input\n",
    "features = [\"맑음\", \"흐림\", \"비\", \"눈\", \"안개\", \"인구수\", \"월\"]\n",
    "X_predict = X_predict[features]\n",
    "\n",
    "# Use the trained model to predict ARI values\n",
    "y_pred = model.predict(X_predict)\n",
    "\n",
    "# Add predictions to the result DataFrame\n",
    "result_df[\"Predicted ARI\"] = y_pred\n",
    "\n",
    "# Display the final DataFrame with predictions\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620801ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[\"Predicted ARI\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690541c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned data\n",
    "import pandas as pd\n",
    "\n",
    "# Try different encodings to read the file\n",
    "file_path = 'Final_Cleaned_Dataset.csv'\n",
    "\n",
    "try:\n",
    "    final_cleaned_data = pd.read_csv(file_path, encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    try:\n",
    "        final_cleaned_data = pd.read_csv(file_path, encoding='euc-kr')  # Common for Korean text\n",
    "    except UnicodeDecodeError:\n",
    "        final_cleaned_data = pd.read_csv(file_path, encoding='latin1')  # Fallback encoding\n",
    "\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    \"지역\": [\"동구\", \"중구\", \"서구\", \"유성구\", \"대덕구\"],\n",
    "    \"Predicted ARI\": [\n",
    "        result_df[\"Predicted ARI\"][0],  # Use the first prediction dynamically\n",
    "        result_df[\"Predicted ARI\"][1],  # Placeholder or dynamic value\n",
    "        result_df[\"Predicted ARI\"][2],  # Placeholder or dynamic value\n",
    "        result_df[\"Predicted ARI\"][3],  # Placeholder or dynamic value\n",
    "        result_df[\"Predicted ARI\"][4]   # Placeholder or dynamic value\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Ensure column names and data types match\n",
    "final_cleaned_data['지역'] = final_cleaned_data['지역'].astype(str).str.strip()\n",
    "\n",
    "\n",
    "# Merge the datasets\n",
    "final_cleaned_data = final_cleaned_data.merge(\n",
    "    result_df[[\"지역\", \"Predicted ARI\"]],\n",
    "    left_on=\"지역\",\n",
    "    right_on=\"지역\",\n",
    "    how=\"left\"\n",
    ").drop(columns=[\"지역\"])\n",
    "\n",
    "# Display the updated dataset\n",
    "print(final_cleaned_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1514f083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "from branca.element import Template, MacroElement\n",
    "\n",
    "\n",
    "# 데이터 불러오기 함수 정의\n",
    "def load_data(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8-sig')\n",
    "    except UnicodeDecodeError:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding='euc-kr')\n",
    "        except UnicodeDecodeError as e:\n",
    "            print(\"파일을 읽는 데 실패했습니다.\")\n",
    "            print(e)\n",
    "            exit()\n",
    "    return df\n",
    "\n",
    "# 데이터 필터링 및 필요한 열 선택 함수 정의\n",
    "def filter_data(df):\n",
    "    required_columns = ['경도', '위도', 'Predicted ARI']\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        print(f\"누락된 열이 있습니다: {missing_columns}\")\n",
    "        exit()\n",
    "    \n",
    "    result_df = df[required_columns].dropna(subset=['경도', '위도', 'Predicted ARI'])\n",
    "    result_df.rename(columns={'Predicted ARI': 'Predicted ARI'}, inplace=True)\n",
    "    print(f\"경도, 위도, ARI 값이 있는 데이터 수: {len(result_df)}\")\n",
    "    return result_df\n",
    "\n",
    "# ARI 값에 따라 색상 및 단계 계산 함수 정의\n",
    "def get_color_and_stage(ari, min_ari, max_ari):\n",
    "    normalized_value = (ari - min_ari) / (max_ari - min_ari)\n",
    "    colors = [\"#00FF00\", \"#FFFF00\", \"#FFA500\", \"#FF0000\"]\n",
    "    stages = [1, 2, 3, 4]\n",
    "    \n",
    "    for i, threshold in enumerate([0.25, 0.5, 0.75, 1.0]):\n",
    "        if normalized_value <= threshold:\n",
    "            return colors[i], stages[i]\n",
    "    \n",
    "    return colors[-1], stages[-1]  # 최대값 초과 시 마지막 단계 반환\n",
    "\n",
    "# 지도 생성 및 표시 함수 정의\n",
    "def create_map(df):\n",
    "    center_lat = df['위도'].mean()\n",
    "    center_lon = df['경도'].mean()\n",
    "    mymap = folium.Map(location=[center_lat, center_lon], zoom_start=12)\n",
    "    \n",
    "    max_ari = df['Predicted ARI'].max()\n",
    "    min_ari = df['Predicted ARI'].min()\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        color, stage = get_color_and_stage(row['Predicted ARI'], min_ari, max_ari)\n",
    "        \n",
    "        folium.CircleMarker(\n",
    "            location=[row['위도'], row['경도']],\n",
    "            radius=5,\n",
    "            color=color,\n",
    "            fill=True,\n",
    "            fill_color=color,\n",
    "            fill_opacity=0.7,\n",
    "            popup=f\"Predicted ARI: {row['Predicted ARI']:.2f}, 단계: {stage}\"\n",
    "        ).add_to(mymap)\n",
    "    \n",
    "    # 범례 추가\n",
    "    legend_html = '''\n",
    "    {% macro html(this, kwargs) %}\n",
    "    <div style=\"position: fixed; bottom: 50px; right: 50px; width: 120px; height: 120px; \n",
    "                border:2px solid grey; z-index:9999; font-size:14px; background-color:white;\n",
    "                \">&nbsp; <b>ARI 단계</b> <br>\n",
    "      &nbsp; <i class=\"fa fa-circle fa-1x\" style=\"color:#FF0000\"></i> 4단계 <br>\n",
    "      &nbsp; <i class=\"fa fa-circle fa-1x\" style=\"color:#FFA500\"></i> 3단계 <br>\n",
    "      &nbsp; <i class=\"fa fa-circle fa-1x\" style=\"color:#FFFF00\"></i> 2단계 <br>\n",
    "      &nbsp; <i class=\"fa fa-circle fa-1x\" style=\"color:#00FF00\"></i> 1단계 <br>\n",
    "    </div>\n",
    "    {% endmacro %}\n",
    "    '''\n",
    "    \n",
    "    macro = MacroElement()\n",
    "    macro._template = Template(legend_html)\n",
    "    mymap.get_root().add_child(macro)\n",
    "    \n",
    "    return mymap\n",
    "\n",
    "# 메인 함수\n",
    "def main():\n",
    "    # Update file_path with the correct dataset path\n",
    "    result_df = final_cleaned_data\n",
    "    \n",
    "    if result_df.empty:\n",
    "        print(\"필터링된 데이터가 없습니다. 프로그램을 종료합니다.\")\n",
    "        return\n",
    "    \n",
    "    mymap = create_map(result_df)\n",
    "    return mymap\n",
    "\n",
    "# 실행\n",
    "mymap = main()\n",
    "mymap\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
